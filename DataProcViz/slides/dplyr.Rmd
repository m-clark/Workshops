```{r setupDplyr, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = T, message=F, warning=F, comment=NA, autodep=T, eval=FALSE, cache=FALSE,
                      R.options=list(width=120), fig.width=8, fig.align = 'center')
```


## 

<div style="text-align:center;font-variant:small-caps; font-size:200%; color:#1e90ff">plyr, dplyr, tidyr</div>


## plyr

Original data managment package of the three.

More general than dplyr.

Not as useful for most common operations, but contains:

>- more flexible versions of the apply family
>- some very useful functions not found elsewhere

## plyr

**ad**ply, **dl**ply etc.

- First letter is the current object
- Second letter is the returned object

```{r eval=T}
library(plyr)
x = list(var1=1:5, var2=2:6)
ldply(x)
ldply(x, sum)
```

Option to parallelize.



## plyr: some useful functions

*ply: apply style functions, with parallel capability

join_all: Recursively join a list of data frames

rbind.fill: Combine data.frames by row, filling in missing columns.

mapvalues/revalue: replace values

round_any: Round to multiple of any number.



## dplyr

Grammar of data manipulation.

Next iteration of plyr.

Focused on tools for working with data frames.

- Over 100 functions

It has three main goals:

- Make the most important data manipulation tasks easier.

- Do them faster.

- Use the same interface to work with data frames, a data tables or database.



## dplyr

Some key operations:


select: grab columns

  - select helpers: one\_of, starts\_with, num_range etc.

filter/slice: grab rows

group_by: grouped operations

mutate/transmute: create new variables

summarize: summarise/aggregate

do: arbitrary operations


## dplyr


Various join/merge functions.

Little things like:

- n, n\_distinct, nth, n\_groups, count, recode

No need to quote variable names


## An example

Let's say we want to select from our data the following variables:

  - Start with the **ID** variable
  - The variables **X1:X10**, which are not all together, and there are many more *X* columns
  - The variables **var1** and **var2**, which are the only *var* variables in the data
  - Any variable that starts with **XYZ**
    
How might we go about this?

## Some base R approaches

Tedious, or typically two steps just to get the columns you want.

```{r baseRexample1, eval=FALSE}
# numeric indexes; not conducive to readibility or reproducibility
newData = oldData[,c(1,2,3,4, etc.)]

# explicitly by name; fine if only a handful; not pretty
newData = oldData[,c('ID','X1', 'X2', etc.)]

# two step with grep; regex difficult to read/understand
cols = c('ID', paste0('X', 1:10), 'var1', 'var2', grep(colnames(oldData), '^XYZ', value=T))
newData = oldData[,cols]

# or via subset
newData = subset(oldData, select = cols)
```


## More
What if you also want observations where **Z** is **Yes**, Q is **No**, and only the observations with the top 50 values of **var2**, ordered by **var1** (descending)?

```{r baseRexample2, eval=FALSE}
# three operations and overwriting or creating new objects if we want clarity
newData = newData[oldData$Z == 'Yes' & oldData$Q == 'No',]
newData = newData[order(newData$var2, decreasing=T)[1:50],]
newData = newData[order(newData$var1, decreasing=T),]
```

And this is for fairly straightforward operations.


## An alternative

```{r pipeExample, eval=FALSE}
newData = oldData %>% 
  filter(Z == 'Yes', Q == 'No') %>% 
  select(num_range('X', 1:10), contains('var'), starts_with('XYZ')) %>% 
  top_n(var2, n=50) %>% 
  arrange(desc(var1))
```



## An alternative


dplyr and piping is an *alternative*

- you can do all this sort of stuff with base R
- <span class="func">with</span>, <span class="func">within</span>, <span class="func">subset</span>, <span class="func">transform</span>, etc.

Even though the initial base R approach depicted is fairly concise, it still can be potentially: 

>- noisier
>- less legible
>- less amenable to additional data changes
>- requires esoteric knowledge (e.g. regular expressions)
>- often requires new objects (even if we just want to explore)




## tidyr

Two primary functions for manipulating data

- gather: wide to long
- spread: long to wide

Other useful functions include:

- unite: paste together multiple columns into one
- spread: complement of unite


## Example


```{r eval=T}
library(tidyr)
stocks <- data.frame( time = as.Date('2009-01-01') + 0:9,
                      X = rnorm(10, 0, 1),
                      Y = rnorm(10, 0, 2),
                      Z = rnorm(10, 0, 4) )
stocks %>% head
stocks %>% gather(stock, price, -time) %>% head
```


## Personal Opinion

I find the dplyr grammar to be clear for a lot of standard data processing.

The best usage of it is for on-the-fly data exploration and visualization.

- No need to create/overwrite existing objects
- Can overwrite columns as they are created
- Makes it easy to look at anything, and do otherwise tedious data checks

Drawbacks:

- not as fast as data.table for many things
- the *mindset* can make for unnecessary complication
    - e.g. no need to pipe etc. to create one new variable