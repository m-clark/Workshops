```{r setupDplyr, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = T, message=F, warning=F, comment=NA, autodep=T, eval=FALSE, cache=FALSE,
                      R.options=list(width=120), fig.width=8, fig.align = 'center')
```


## 

<div style="text-align:center;font-variant:small-caps; font-size:200%; color:#1e90ff">plyr, dplyr, tidyr</div>


## plyr

Original data managment package of the three.

More general than <span class="pack">dplyr.</span>

Not as useful for most common operations, but contains:

>- more flexible versions of the apply family
>- some very useful functions not found elsewhere

## plyr

<span class="func">**ad**ply</span>, <span class="func">**dl**ply</span> etc.

- First letter represents the current object (array, data.frame, list)
- Second letter represents the returned object

```{r eval=T}
library(plyr)
x = list(var1=1:5, var2=2:6)
ldply(x)
ldply(x, sum)
```

Option to parallelize.



## plyr: some useful functions

*ply: apply style functions, with parallel capability

<span class="func">join_all</span>: Recursively join a list of data frames

<span class="func">rbind.fill</span>: row bind data.frames, filling in missing columns.

<span class="func">mapvalues</span>/<span class="func">revalue</span>: replace values

<span class="func">round_any</span>: Round to multiple of any number.



## dplyr

Grammar of data manipulation.

Next iteration of <span class="func">plyr</span>.

Focused on tools for working with data frames.

- Over 100 functions

It has three main goals:

- Make the most important data manipulation tasks easier.

- Do them faster.

- Use the same interface to work with data frames, a data tables or database.



## dplyr

Some key operations:


<span class="func">select</span>: grab columns

  - select helpers: <span class="func">one\_of</span>, <span class="func">starts\_with</span>, <span class="func">num_range</span> etc.

<span class="func">filter</span>/<span class="func">slice</span>: grab rows

<span class="func">group_by</span>: grouped operations

<span class="func">mutate</span>/<span class="func">transmute</span>: create new variables

<span class="func">summarize</span>: summarise/aggregate

<span class="func">do</span>: arbitrary operations


## dplyr


Various join/merge functions.

Little things like:

- <span class="func">n</span>, <span class="func">n\_distinct</span>, <span class="func">nth</span>, <span class="func">n\_groups</span>, <span class="func">count</span>, <span class="func">recode</span>, <span class="func">between</span>

No need to quote variable names.


## An example

Let's say we want to select from our data the following variables:

  - Start with the **ID** variable
  - The variables **X1:X10**, which are not all together, and there are many more *X* columns
  - The variables **var1** and **var2**, which are the only *var* variables in the data
  - Any variable that starts with **XYZ**
    
How might we go about this?

## Some base R approaches

Tedious, or typically two steps just to get the columns you want.

```{r baseRexample1, eval=FALSE}
# numeric indexes; not conducive to readibility or reproducibility
newData = oldData[,c(1,2,3,4, etc.)]

# explicitly by name; fine if only a handful; not pretty
newData = oldData[,c('ID','X1', 'X2', etc.)]

# two step with grep; regex difficult to read/understand
cols = c('ID', paste0('X', 1:10), 'var1', 'var2', grep(colnames(oldData), '^XYZ', value=T))
newData = oldData[,cols]

# or via subset
newData = subset(oldData, select = cols)
```


## More
What if you also want observations where **Z** is **Yes**, Q is **No**, and only the observations with the top 50 values of **var2**, ordered by **var1** (descending)?

```{r baseRexample2, eval=FALSE}
# three operations and overwriting or creating new objects if we want clarity
newData = newData[oldData$Z == 'Yes' & oldData$Q == 'No',]
newData = newData[order(newData$var2, decreasing=T)[1:50],]
newData = newData[order(newData$var1, decreasing=T),]
```

And this is for fairly straightforward operations.


## An alternative

```{r pipeExample, eval=FALSE}
newData = oldData %>% 
  filter(Z == 'Yes', Q == 'No') %>% 
  select(num_range('X', 1:10), contains('var'), starts_with('XYZ')) %>% 
  top_n(var2, n=50) %>% 
  arrange(desc(var1))
```



## An alternative


<span class="pack">dplyr</span> and piping is an *alternative*

- you can do all this sort of stuff with base R
- <span class="func">with</span>, <span class="func">within</span>, <span class="func">subset</span>, <span class="func">transform</span>, etc.

Even though the initial base R approach depicted is fairly concise, it still can potentially be: 

>- noisier
>- less legible
>- less amenable to additional data changes
>- requires esoteric knowledge (e.g. regular expressions)
>- often requires new objects (even if we just want to explore)



## tidyr

Two primary functions for manipulating data

- <span class="func">gather</span>: wide to long
- <span class="func">spread</span>: long to wide

Other useful functions include:

- <span class="func">unite</span>: paste together multiple columns into one
- <span class="func">separate</span>: complement of unite



## Example

```{r eval=T}
library(tidyr)
stocks <- data.frame( time = as.Date('2009-01-01') + 0:9,
                      X = rnorm(10, 0, 1),
                      Y = rnorm(10, 0, 2),
                      Z = rnorm(10, 0, 4) )
stocks %>% head
stocks %>% gather(stock, price, -time) %>% head
```


## Personal Opinion

The <span class="pack">dplyr</span> grammar is clear for a lot of standard data processing tasks, and some not so common.

Extremely useful for data exploration and visualization.

- No need to create/overwrite existing objects
- Can overwrite columns as they are created
- Makes it easy to look at anything, and do otherwise tedious data checks

Drawbacks:

- not as fast as <span class="pack">data.table</span> for many things
- the *mindset* can make for unnecessary complication
    - e.g. no need to pipe etc. to create one new variable
    
    
## On the horizon

<span class="pack">multidplyr</span>

Partitions the data across a cluster.

Faster than data.table (after partitioning)