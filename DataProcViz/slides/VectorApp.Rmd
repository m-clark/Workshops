```{r setupVector, include=FALSE}
knitr::opts_chunk$set(echo = T, message=F, warning=F, comment=NA, autodep=T, eval=F,
                      R.options=list(width=120), fig.width=8, fig.align = 'center')
```

## 

<div style="text-align:center;font-variant:small-caps; font-family:TRON; font-size:200%; color:#1e90ff">Vectorization</div>

## Boolean Indexing

We can take values corresponding to some operation that results in `TRUE` or `FALSE`.

Assume x is a vector of numbers.

```{r boolindex}
idx = x > 2
idx
x[idx]
```

## Flexiblity

We actually don't have to create a Boolean object before using it. 

R indexing is ridiculously flexible.

```{r flexindex}
x[x > 2]
x[x != 3]
x[ifelse(x > 2, T, F)]
x[{y = idx; y}]
```

## Vectorized operations

Consider the following loop:

```{r loop}
for (i in 1:nrow(mydf)) {
  check = mydf$x[i] > 2
  if (check==TRUE){
    mydf$y[i] = 'Yes'
  } else {
    mydf$y[i] = 'No'
  }
}
```


## Vectorized operations

Compare:

```{r boolnoloop}
mydf$y = 'No'
mydf$y[mydf$x > 2] = 'Yes'
```

This gets us the same thing.



## Vectorized operations

Boolean indexing provides an example of a vectorized operation.

The whole vector is considered rather than each element individually.

This is always faster.

## Vectorized operations

Log all values in a matrix.

```{r vecmatrixop}
mymatrix_log = log(mymatrix)
```

Would be a lot faster than looping over elements, rows or columns.



## Vectorized Operations

Many vectorized functions already exist in R.

They are also often written in C, Fortran etc., and so even faster.
  

## Apply functions

In R there a family of functions that allow for a succinct way of looping.

- apply
- lapply, sapply, vapply
- tapply
- mapply
- replicate



## Apply functions

- apply
    - arrays, matrices, data.frames
- lapply, sapply, vapply
    - lists, data.frames, vectors
- tapply
    - grouped operations (table apply)
- mapply
    - multivariate version of sapply
- replicate
    - similar to sapply
    
## Example

Standardizing variables

```{r loopvsapply1, eval=FALSE}
for (i in 1:ncol(mydf)){
  x = mydf[,i]
  for (j in 1:length(x)){
    x[j] = (x[j] - mean(x))/sd(x)
  }
}
```

This would be a really bad way to use R.

```{r loopvsapply2, eval=-3}
stdize <- function(x) {
  (x-mean(x))/sd(x)
}

apply(mydf, 2, stdize)
```

## Timings

```{r timings, echo=F, eval=TRUE, cache=TRUE}
mydf = matrix(rnorm(100000), ncol=1000)
doubleloop = function(){
  for (i in 1:ncol(mydf)){
  x = mydf[,i]
  for (j in 1:length(x)){
    x[j] = (x[j] - mean(x))/sd(x)
  }
}
}


singleloop = function(){
  for (i in 1:ncol(mydf)){
  x = mydf[,i]
  x = (x - mean(x))/sd(x)
  }
}

library(plyr)

test = microbenchmark::microbenchmark(doubleloop=doubleloop(),
                                      singleloop=singleloop(), 
                                      plyr=aaply(mydf, 2, stdize),
                                      apply=apply(mydf, 2, stdize), 
                                      vectorized=scale(mydf), times=25)
test
```

    
## Apply functions

Benefits
  
  - Cleaner/simpler code
  - Possibly reproducible
      - more likely to use generalizable functions
  - Parallelizable
    
<span class="emph">NOT</span> faster than explict loops.

- single loop over columns was as fast as apply
- Replicate and mapply are especially slow

ALWAYS can *potentially* be faster than loops.

  - Parallelization: parApply, parLapply etc.



## Personal experience

I use R every day, and I only use a loop for a sequential operation.

- Note: no speed difference for a for loop vs. using while
- If you must use an explicit loop, create an empty object and fill in
    - Fastet

I never use a double loop.



## Apply functions

Using apply functions should be a part of your regular R experience.

Other versions we'll talk about have been optimized.

However, you need to know the basics in order to use those.

Any you still may need parallel versions.